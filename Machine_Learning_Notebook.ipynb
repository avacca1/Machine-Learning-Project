{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ684dx-kqtG",
        "outputId": "a2885331-7226-4072-d8fb-b52c86e5ee68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, r2_score\n",
        "from sklearn.cluster import KMeans\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from nltk.stem.porter import *\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def minmax(data, col):\n",
        "    new_data = data\n",
        "    max_num = np.max(new_data[:,col])\n",
        "    min_num = np.min(new_data[:,col])\n",
        "\n",
        "    for i in range(new_data.shape[0]):\n",
        "        new_data[i][col] = (new_data[i][col] - min_num) / (max_num - min_num)\n",
        "    \n",
        "    return new_data"
      ],
      "metadata": {
        "id": "Khr102HnktEl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeData(n_samples=93240,n_features=11,dataPath=\"News_Final.csv\"):\n",
        "    data = pd.read_csv(dataPath)\n",
        "    data[\"PublishDate\"] = pd.to_datetime(data[\"PublishDate\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
        "    data['PublishDate'] = data['PublishDate'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "    data = data.to_numpy()\n",
        "    \n",
        "    labels = data[:n_samples,-3:]\n",
        "    X = data[:n_samples,:-3]\n",
        "    \n",
        "    # omitting rows with no usable labels\n",
        "    bool_matrix = np.any(labels != 0, axis=1)\n",
        "    labels = labels[bool_matrix]\n",
        "    X = X[bool_matrix]\n",
        "    \n",
        "    bool_matrix = labels[:, 1] != -1\n",
        "    labels = labels[bool_matrix]\n",
        "    X = X[bool_matrix]\n",
        "\n",
        "\n",
        "    ### changing the lables \n",
        "    minmax(labels,0)\n",
        "    minmax(labels,1)\n",
        "    minmax(labels,2)\n",
        "    minmax(X,5)\n",
        "\n",
        "    Y_new = np.zeros(labels.shape[0])\n",
        "    for i in range(labels.shape[0]):\n",
        "        if labels[i][0] == -1 and labels[i][1] == -1 and labels[i][2] == -1:\n",
        "            Y_new[i] = -1\n",
        "\n",
        "        if labels[i][0] >= labels[i][1] and labels[i][0] >= labels[i][1]:\n",
        "            Y_new[i] = 0\n",
        "        elif labels[i][1] >= labels[i][0] and labels[i][1] >= labels[i][2]:\n",
        "            Y_new[i] = 1\n",
        "        elif labels[i][2] >= labels[i][1] and labels[i][2] >= labels[i][0]:\n",
        "            Y_new[i] = 2\n",
        "\n",
        "    labels = Y_new\n",
        "    ###\n",
        "    \n",
        "    \n",
        "    return X,labels"
      ],
      "metadata": {
        "id": "eAHEBUMHkuM4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def splitData(X, labels, test_size, seed):\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    indices = range(X.shape[0])\n",
        "    train_indices = np.random.choice(indices,size = int(len(indices) * (1-test_size)),replace=False)\n",
        "    test_indices = np.setdiff1d(indices,train_indices)\n",
        "    \n",
        "    X_train = X[train_indices]\n",
        "    X_test = X[test_indices]  \n",
        "    \n",
        "    y_train = labels[train_indices]\n",
        "    y_test = labels[test_indices]\n",
        "    \n",
        "    return X_train,X_test,y_train,y_test"
      ],
      "metadata": {
        "id": "5AicWSXvkv50"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.internals.blocks import final\n",
        "class NewsData(object):\n",
        "    def __init__(self):\n",
        "        self.X, self.labels = makeData(5000)\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = splitData(self.X,self.labels, 0.2, 2023)\n",
        "        self.encoder = OneHotEncoder()\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.tfidf = None\n",
        "        self.corpus = []\n",
        "        \n",
        "    def OneHotEncodeTrain(self, index):\n",
        "        col = np.array(self.X_train[:,index]).reshape(-1, 1)\n",
        "        self.encoder.fit(col)\n",
        "        one_hot_data = self.encoder.transform(col).toarray()\n",
        "        for i in range(self.X_train.shape[0]):\n",
        "            self.X_train[i][index] = list(one_hot_data[i])\n",
        "            \n",
        "    def OneHotEncodeTest(self, index):\n",
        "        col = np.array(self.X_test[:,index]).reshape(-1, 1)\n",
        "        self.encoder.fit(col)\n",
        "        one_hot_data = self.encoder.transform(col).toarray()\n",
        "        for i in range(self.X_test.shape[0]):\n",
        "            self.X_test[i][index] = list(one_hot_data[i])\n",
        "    \n",
        "    def getCorpus(self, index):\n",
        "        col = np.array(self.X_train[:,index]).reshape(-1, 1)\n",
        "        col = [str(x) for x in col]\n",
        "\n",
        "        row_strings = [''.join(row) for row in col]\n",
        "        final_string = ''.join(row_strings)\n",
        "\n",
        "        tokens = word_tokenize(final_string)\n",
        "\n",
        "        stemmer = PorterStemmer()\n",
        "        stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "        final_string = np.unique(stemmed_tokens)\n",
        "\n",
        "        self.corpus.append(final_string.tolist())\n",
        "\n",
        "    def combineCorpus(self):\n",
        "        i = 1\n",
        "        while i < len(self.corpus):\n",
        "            for x in self.corpus[i]:\n",
        "                self.corpus[0].append(str(x))\n",
        "            i+=1\n",
        "        self.corpus = self.corpus[0]\n",
        "        self.corpus = np.unique(self.corpus).tolist()\n",
        "        self.corpus = pd.DataFrame(self.corpus, columns=['words'])\n",
        "\n",
        "    def vectorizeTrain(self, index):\n",
        "        if self.tfidf is None:\n",
        "            self.tfidf = self.vectorizer.fit_transform(self.corpus['words'].values.astype('U'))\n",
        "        for i in range(self.X_train.shape[0]):\n",
        "            if type(self.X_train[i][index]) != type('str'):\n",
        "                self.X_train[i][index] = \"\"\n",
        "            self.X_train[i][index] = (self.vectorizer.transform([self.X_train[i][index]]))\n",
        "    \n",
        "    def vectorizeTest(self, index):\n",
        "        if self.tfidf is None:\n",
        "            self.tfidf = self.vectorizer.fit_transform(self.corpus['words'].values.astype('U'))\n",
        "        for i in range(self.X_test.shape[0]):\n",
        "            if type(self.X_test[i][index]) != type('str'):\n",
        "                self.X_test[i][index] = \"\"\n",
        "            self.X_test[i][index] = (self.vectorizer.transform([self.X_test[i][index]]))\n",
        "\n",
        "        return self.tfidf.toarray()\n",
        "    \n",
        "\n",
        "    def makeCorpus(self, col_num):\n",
        "        \n",
        "        col_train = self.X_train[:, col_num]\n",
        "        col_test = self.X_test[:, col_num]\n",
        "\n",
        "        \n",
        "        stemmer = PorterStemmer()\n",
        "        for col in [col_train, col_test]:\n",
        "            for sentence in col:\n",
        "                words = word_tokenize(sentence.lower())\n",
        "                stemmed_words = [stemmer.stem(word) for word in words]\n",
        "                self.corpus.extend(stemmed_words)\n",
        "\n",
        "        self.corpus = list(set(self.corpus))\n",
        "\n",
        "    def get_top_words(self, numwords = 100):\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        vectorizer.fit_transform([' '.join(self.corpus)])\n",
        "\n",
        "        feature_names = list(vectorizer.vocabulary_.keys())\n",
        "        tfidf_scores = vectorizer.transform([' '.join(self.corpus)])\n",
        "\n",
        "\n",
        "        top_keywords_idx = tfidf_scores.toarray()[0].argsort()[::-1][:numwords]\n",
        "        top_keywords = [feature_names[i] for i in top_keywords_idx]\n",
        "\n",
        "        return top_keywords\n",
        "    \n",
        "    def count_top_words(self):\n",
        "\n",
        "        top_keywords = self.get_top_words()\n",
        "\n",
        "        count_train = np.zeros((self.X_train.shape[0], len(top_keywords)))\n",
        "        count_test = np.zeros((self.X_test.shape[0], len(top_keywords)))\n",
        "\n",
        "        for i, keyword in enumerate(top_keywords):\n",
        "\n",
        "\n",
        "            for j, sentence in enumerate(self.X_train[:, 1]):\n",
        "                words = word_tokenize(sentence.lower())\n",
        "                stemmed_words = [PorterStemmer().stem(word) for word in words]\n",
        "                count_train[j][i] = stemmed_words.count(keyword)\n",
        "\n",
        "\n",
        "            for j, sentence in enumerate(self.X_train[:, 2]):\n",
        "                words = word_tokenize(sentence.lower())\n",
        "                stemmed_words = [PorterStemmer().stem(word) for word in words]\n",
        "                count_train[j][i] += stemmed_words.count(keyword)\n",
        "\n",
        "\n",
        "            for j, sentence in enumerate(self.X_test[:, 1]):\n",
        "                words = word_tokenize(sentence.lower())\n",
        "                stemmed_words = [PorterStemmer().stem(word) for word in words]\n",
        "                count_test[j][i] += stemmed_words.count(keyword)\n",
        "\n",
        "            \n",
        "            for j, sentence in enumerate(self.X_test[:, 2]):\n",
        "                words = word_tokenize(sentence.lower())\n",
        "                stemmed_words = [PorterStemmer().stem(word) for word in words]\n",
        "                count_test[j][i] += stemmed_words.count(keyword)\n",
        "\n",
        "        self.X_train = np.concatenate((self.X_train, count_train), axis=1)\n",
        "        self.X_test = np.concatenate((self.X_test, count_test), axis=1)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "mnw5nkQAkyCm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newsData = NewsData()\n",
        "newsData.OneHotEncodeTrain(3)\n",
        "newsData.OneHotEncodeTrain(4)\n",
        "\n",
        "print(\"1\")\n",
        "newsData.OneHotEncodeTest(3)\n",
        "newsData.OneHotEncodeTest(4)\n",
        "print(\"2\")\n",
        "newsData.makeCorpus(1)\n",
        "newsData.makeCorpus(2)\n",
        "newsData.get_top_words(10)\n",
        "newsData.count_top_words()\n",
        "newsData.X_train = np.delete(newsData.X_train, 1, axis=1)\n",
        "newsData.X_train = np.delete(newsData.X_train, 1, axis=1)\n",
        "# np.concatenate((newsData.X_train, newsData.X_train[]), axis=1)\n",
        "newsData.X_train = np.delete(newsData.X_train, 1, axis=1)\n",
        "newsData.X_train = np.delete(newsData.X_train, 1, axis=1)\n",
        "newsData.X_test = np.delete(newsData.X_test, 1, axis=1)\n",
        "newsData.X_test = np.delete(newsData.X_test, 1, axis=1)\n",
        "newsData.X_test = np.delete(newsData.X_test, 1, axis=1)\n",
        "newsData.X_test = np.delete(newsData.X_test, 1, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfJb0-SlR0U4",
        "outputId": "44d2c998-d3a8-4f06-fb61-e9de7d8b377c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(newsData.X_train))\n",
        "print((newsData.y_train.shape))\n",
        "\n",
        "kmeans_X_train = np.column_stack((newsData.X_train, newsData.y_train))\n",
        "kmeans_X_test = np.column_stack((newsData.X_test, newsData.y_test))\n",
        "print(kmeans_X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0TQx0f1XRPI",
        "outputId": "47d970d2-6af8-4e37-f1bc-0f0d57390178"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(2456,)\n",
            "[[3437.0 0.8874523658137077 0.0 ... 0.0 0.0 1.0]\n",
            " [1699.0 0.372209005124491 0.0729166666666665 ... 0.0 0.0 0.0]\n",
            " [1388.0 0.31147052259702634 0.0441941738241592 ... 0.0 0.0 0.0]\n",
            " ...\n",
            " [2862.0 0.7360158661316198 0.125988157669742 ... 0.0 0.0 0.0]\n",
            " [3600.0 0.9179214020135839 -0.220970869120796 ... 0.0 0.0 0.0]\n",
            " [2532.0 0.6501282175445393 -0.0188444590361102 ... 0.0 0.0 0.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainarr = KMeans(n_clusters=3, random_state=0, n_init=\"auto\").fit_transform(newsData.X_train)\n",
        "testarr = KMeans(n_clusters=3, random_state=0, n_init=\"auto\").fit_transform(newsData.X_test)\n",
        "kmeans = KMeans(n_clusters=3, random_state=0, n_init=\"auto\").fit(trainarr)"
      ],
      "metadata": {
        "id": "hzMzBxG7UkXy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import linear_sum_assignment\n",
        "def evaluate_clustering(trained_model, X, labels):\n",
        "    \"\"\"\n",
        "    Compute the ratio of correct matches between clusters from the trained model and the true labels\n",
        "    :param trained_model: Unsupervised learning model that predicts clusters\n",
        "    :param X: samples array, shape (num_samples, num_features)\n",
        "    :param labels: true labels array, shape (num_samples,\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # We can assume that the number of clusters and the number of class labels are the same\n",
        "    clusters = trained_model.predict(X)\n",
        "    # Workspace 1.7\n",
        "    #BEGIN \n",
        "    cost = np.zeros((np.unique(labels).shape[0],np.unique(labels).shape[0]))\n",
        "    for x,y in np.column_stack((clusters.astype(int),labels.astype(int))):\n",
        "        cost[x][y] -= 1\n",
        "    #X mapping\n",
        "    row_ind, col_ind = linear_sum_assignment(cost)\n",
        "    accuracy = np.abs(cost[row_ind,col_ind].sum())/clusters.shape[0]\n",
        "    \n",
        "    \n",
        "    #END\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "-5HpviSqbmTf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "accuracies = []\n",
        "for i in range(20):\n",
        "    trainarr = KMeans(n_clusters=3, n_init=\"auto\").fit_transform(newsData.X_train)\n",
        "    testarr = KMeans(n_clusters=3, n_init=\"auto\").fit_transform(newsData.X_test)\n",
        "    kmeans = KMeans(n_clusters=3, n_init=\"auto\").fit(trainarr)\n",
        "    accuracies.append(evaluate_clustering(kmeans, testarr, newsData.y_test))\n",
        "plt.hist(accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "U3K8OS4SaiAW",
        "outputId": "c8c5d880-d211-438c-966a-28fcaf39ad61"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([8., 1., 1., 3., 0., 0., 0., 0., 0., 7.]),\n",
              " array([0.35609756, 0.37252033, 0.38894309, 0.40536585, 0.42178862,\n",
              "        0.43821138, 0.45463415, 0.47105691, 0.48747967, 0.50390244,\n",
              "        0.5203252 ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "\n",
        "print(\"Mode:\",scipy.stats.mode(accuracies))\n",
        "print(\"Mean:\",np.mean(accuracies))\n",
        "print(\"Median:\",np.median(accuracies))\n",
        "print(\"Highest:\",np.max(accuracies))\n",
        "print(\"Lowest:\",np.min(accuracies))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koVgiSe_BsvO",
        "outputId": "94f6b220-ecf4-491e-b8bc-b84b209541e6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode: ModeResult(mode=array([0.5203252]), count=array([7]))\n",
            "Mean: 0.4284552845528455\n",
            "Median: 0.40731707317073174\n",
            "Highest: 0.5203252032520326\n",
            "Lowest: 0.35609756097560974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-76da8ec8a361>:3: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  print(\"Mode:\",scipy.stats.mode(accuracies))\n"
          ]
        }
      ]
    }
  ]
}